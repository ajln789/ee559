{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Implementing gradient descent correctly can be tricky, especially as the complexity of the model increases. Different variations of gradient descent are more powerful and robust than the absolute basic example above, but the core idea remains the same. When we run into problems where gradient descent does not always find the same set of weights, its important that we utilize a reliable implementation. We'll use [CVX](https://www.cvxpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cvxpy as cvx #import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct the problem.\n",
    "w = cvx.Variable(2)  #here we declare the variable we want to find, the 2 dimensional weight vector  \n",
    "objective = cvx.Minimize(cvx.sum_squares(X*w - Y))  # here we define our loss function\n",
    "                                                    # careful of the * operator, CVX uses shorthand operations\n",
    "prob = cvx.Problem(objective)\n",
    "\n",
    "# The optimal objective value is returned by `prob.solve()`.\n",
    "result = prob.solve()\n",
    "# The optimal value for w is stored in `w.value`.\n",
    "print(w.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
